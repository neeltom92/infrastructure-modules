## runbook_url: https://github.com/kubernetes-monitoring/kubernetes-mixin/tree/master/runbook.md

groups:
  - name: node-exporter.rules
    rules:
    - expr: |
        count without (cpu) ( count without (mode) ( node_cpu_seconds_total ) )
      record: instance:node_num_cpu:sum
    - expr: |
        1 - avg without (cpu, mode) (rate(node_cpu_seconds_total{mode="idle"}[1m]))
      record: instance:node_cpu_utilisation:rate1m
    - expr: |
        (
          node_load1{} / instance:node_num_cpu:sum{})
      record: instance:node_load1_per_cpu:ratio
    - expr: |
        1 - ( node_memory_MemAvailable_bytes{} /  node_memory_MemTotal_bytes{} )
      record: instance:node_memory_utilisation:ratio
    - expr: |
        rate(node_vmstat_pgmajfault{}[1m])
      record: instance:node_vmstat_pgmajfault:rate1m
    - expr: |
        rate(node_disk_io_time_seconds_total{device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+"}[1m])
      record: instance_device:node_disk_io_time_seconds:rate1m
    - expr: |
        rate(node_disk_io_time_weighted_seconds_total{device=~"nvme.+|rbd.+|sd.+|vd.+|xvd.+|dm-.+|dasd.+"}[1m])
      record: instance_device:node_disk_io_time_weighted_seconds:rate1m
    - expr: |
        sum without (device) (rate(node_network_receive_bytes_total{device!="lo"}[1m]) )
      record: instance:node_network_receive_bytes_excluding_lo:rate1m
    - expr: |
        sum without (device) (rate(node_network_transmit_bytes_total{device!="lo"}[1m]))
      record: instance:node_network_transmit_bytes_excluding_lo:rate1m
    - expr: |
        sum without (device) ( rate(node_network_receive_drop_total{device!="lo"}[1m]) )
      record: instance:node_network_receive_drop_excluding_lo:rate1m
    - expr: |
        sum without (device) ( rate(node_network_transmit_drop_total{ device!="lo"}[1m]) )
      record: instance:node_network_transmit_drop_excluding_lo:rate1m
  - name: kube-apiserver.rules
    rules:
    - expr: |
        sum(rate(apiserver_request_duration_seconds_sum{subresource!="log",verb!~"LIST|WATCH|WATCHLIST|PROXY|CONNECT"}[5m])) without(instance, pod) /  sum(rate(apiserver_request_duration_seconds_count{subresource!="log",verb!~"LIST|WATCH|WATCHLIST|PROXY|CONNECT"}[5m])) without(instance, pod)
      record: cluster:apiserver_request_duration_seconds:mean5m
    # - expr: |
    #     histogram_quantile(0.99, sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",subresource!="log",verb!~"LIST|WATCH|WATCHLIST|PROXY|CONNECT"}[5m])) without(instance, pod))
    #   labels:
    #     quantile: "0.99"
    #   record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
    # - expr: |
    #     histogram_quantile(0.9, sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",subresource!="log",verb!~"LIST|WATCH|WATCHLIST|PROXY|CONNECT"}[5m])) without(instance, pod))
    #   labels:
    #     quantile: "0.9"
    #   record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
    # - expr: |
    #     histogram_quantile(0.5, sum(rate(apiserver_request_duration_seconds_bucket{job="apiserver",subresource!="log",verb!~"LIST|WATCH|WATCHLIST|PROXY|CONNECT"}[5m])) without(instance, pod))
    #   labels:
    #     quantile: "0.5"
    #   record: cluster_quantile:apiserver_request_duration_seconds:histogram_quantile
  - name: k8s.rules
    rules:
    - expr: |
        sum by(namespace) (rate(container_cpu_usage_seconds_total{container!="POD",image!=""}[5m]))
      record: namespace:container_cpu_usage_seconds_total:sum_rate
    - expr: |
        sum by(cluster, namespace, pod, container) (rate(container_cpu_usage_seconds_total{container!="POD",image!=""}[5m])) * on(cluster, namespace, pod) group_left(node) max by(cluster, namespace, pod, node) (kube_pod_info)
      record: node_namespace_pod_container:container_cpu_usage_seconds_total:sum_rate
    - expr: |
        container_memory_working_set_bytes{image!=""} * on(namespace, pod) group_left(node) max by(namespace, pod, node) (kube_pod_info)
      record: node_namespace_pod_container:container_memory_working_set_bytes
    - expr: |
        container_memory_rss{image!=""} * on (namespace, pod) group_left(node) max by(namespace, pod, node) (kube_pod_info)
      record: node_namespace_pod_container:container_memory_rss
    - expr: |
        container_memory_cache{image!=""} * on (namespace, pod) group_left(node) max by(namespace, pod, node) (kube_pod_info)
      record: node_namespace_pod_container:container_memory_cache
    - expr: |
        container_memory_swap{image!=""}  * on (namespace, pod) group_left(node) max by(namespace, pod, node) (kube_pod_info)
      record: node_namespace_pod_container:container_memory_swap
    - expr: |
        sum(container_memory_usage_bytes{image!="", container!="POD"}) by (namespace)
      record: namespace:container_memory_usage_bytes:sum
    - expr: |
        sum by (namespace) ( sum by (namespace, pod) ( max by (namespace, pod, container) (  kube_pod_container_resource_requests_memory_bytes{}  ) * on(namespace, pod) group_left() max by (namespace, pod) ( kube_pod_status_phase{phase=~"Pending|Running"} == 1  )  )  )
      record: namespace:kube_pod_container_resource_requests_memory_bytes:sum
    - expr: |
        sum by (namespace) ( sum by (namespace, pod) (  max by (namespace, pod, container) (  kube_pod_container_resource_requests_cpu_cores{}  ) * on(namespace, pod) group_left() max by (namespace, pod) (  kube_pod_status_phase{phase=~"Pending|Running"} == 1 )  ) )
      record: namespace:kube_pod_container_resource_requests_cpu_cores:sum
    - expr: |
        sum( label_replace( label_replace(  kube_pod_owner{owner_kind="ReplicaSet"}, "replicaset", "$1", "owner_name", "(.*)" ) * on(replicaset, namespace) group_left(owner_name) kube_replicaset_owner{}, "workload", "$1", "owner_name", "(.*)"  ) ) by (cluster, namespace, workload, pod)
      labels:
        workload_type: deployment
      record: mixin_pod_workload
    - expr: |
        sum( label_replace( kube_pod_owner{owner_kind="DaemonSet"}, "workload", "$1", "owner_name", "(.*)"  ) ) by (cluster, namespace, workload, pod)
      labels:
        workload_type: daemonset
      record: mixin_pod_workload
    - expr: |
        sum(
          label_replace( kube_pod_owner{owner_kind="StatefulSet"}, "workload", "$1", "owner_name", "(.*)"  )  ) by (cluster, namespace, workload, pod)
      labels:
        workload_type: statefulset
      record: mixin_pod_workload
  # - name: kube-scheduler.rules
  #   rules:
  #   - expr: |
  #       histogram_quantile(0.99, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
  #     labels:
  #       quantile: "0.99"
  #     record: cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile
  #   - expr: |
  #       histogram_quantile(0.99, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
  #     labels:
  #       quantile: "0.99"
  #     record: cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile
  #   - expr: |
  #       histogram_quantile(0.99, sum(rate(scheduler_binding_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
  #     labels:
  #       quantile: "0.99"
  #     record: cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile
  #   - expr: |
  #       histogram_quantile(0.9, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
  #     labels:
  #       quantile: "0.9"
  #     record: cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile
  #   - expr: |
  #       histogram_quantile(0.9, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
  #     labels:
  #       quantile: "0.9"
  #     record: cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile
  #   - expr: |
  #       histogram_quantile(0.9, sum(rate(scheduler_binding_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
  #     labels:
  #       quantile: "0.9"
  #     record: cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile
  #   - expr: |
  #       histogram_quantile(0.5, sum(rate(scheduler_e2e_scheduling_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
  #     labels:
  #       quantile: "0.5"
  #     record: cluster_quantile:scheduler_e2e_scheduling_duration_seconds:histogram_quantile
  #   - expr: |
  #       histogram_quantile(0.5, sum(rate(scheduler_scheduling_algorithm_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
  #     labels:
  #       quantile: "0.5"
  #     record: cluster_quantile:scheduler_scheduling_algorithm_duration_seconds:histogram_quantile
  #   - expr: |
  #       histogram_quantile(0.5, sum(rate(scheduler_binding_duration_seconds_bucket{job="kube-scheduler"}[5m])) without(instance, pod))
  #     labels:
  #       quantile: "0.5"
  #     record: cluster_quantile:scheduler_binding_duration_seconds:histogram_quantile
  - name: node.rules
    rules:
    - expr: |
        sum(min(kube_pod_info) by (cluster, node))
      record: ':kube_pod_info_node_count:'
    - expr: |
        max(label_replace(kube_pod_info{}, "pod", "$1", "pod", "(.*)")) by (node, namespace, pod)
      record: 'node_namespace_pod:kube_pod_info:'
    - expr: |
        count by (cluster, node) (sum by (node, cpu) ( node_cpu_seconds_total{}  * on (namespace, pod) group_left(node)  node_namespace_pod:kube_pod_info:  ))
      record: node:node_num_cpu:sum
    - expr: |
        sum( node_memory_MemAvailable_bytes{} or  ( node_memory_Buffers_bytes{} +  node_memory_Cached_bytes{} +  node_memory_MemFree_bytes{} +  node_memory_Slab_bytes{} )  ) by (cluster)
      record: :node_memory_MemAvailable_bytes:sum
  - name: kube-prometheus-node-recording.rules
    rules:
    - expr: sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait"}[3m])) BY (instance)
      record: instance:node_cpu:rate:sum
    - expr: sum((node_filesystem_size_bytes{mountpoint="/"} - node_filesystem_free_bytes{mountpoint="/"}))  BY (instance)
      record: instance:node_filesystem_usage:sum
    - expr: sum(rate(node_network_receive_bytes_total[3m])) BY (instance)
      record: instance:node_network_receive_bytes:rate:sum
    - expr: sum(rate(node_network_transmit_bytes_total[3m])) BY (instance)
      record: instance:node_network_transmit_bytes:rate:sum
    - expr: sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait"}[5m])) WITHOUT  (cpu, mode) / ON(instance) GROUP_LEFT() count(sum(node_cpu_seconds_total)  BY (instance, cpu)) BY (instance)
      record: instance:node_cpu:ratio
    - expr: sum(rate(node_cpu_seconds_total{mode!="idle",mode!="iowait"}[5m]))
      record: cluster:node_cpu:sum_rate5m
    - expr: cluster:node_cpu_seconds_total:rate5m / count(sum(node_cpu_seconds_total)  BY (instance, cpu))
      record: cluster:node_cpu:ratio
  - name: kube-prometheus-general.rules
    rules:
    - expr: count without(instance, pod, node) (up == 1)
      record: count:up1
    - expr: count without(instance, pod, node) (up == 0)
      record: count:up0
  # - name: kube-state-metrics
  #   rules:
  #   - alert: KubeStateMetricsListErrors
  #     annotations:
  #       message: kube-state-metrics is experiencing errors at an elevated rate in
  #         list operations. This is likely causing it to not be able to expose metrics
  #         about Kubernetes objects correctly or at all.
  #     expr: |
  #       (sum(rate(kube_state_metrics_list_total{job="kube-state-metrics",result="error"}[5m])) /  sum(rate(kube_state_metrics_list_total{job="kube-state-metrics"}[5m])))  > 0.01
  #     for: 15m
  #     labels:
  #       severity: critical
  #   - alert: KubeStateMetricsWatchErrors
  #     annotations:
  #       message: kube-state-metrics is experiencing errors at an elevated rate in
  #         watch operations. This is likely causing it to not be able to expose metrics
  #         about Kubernetes objects correctly or at all.
  #     expr: |
  #       (sum(rate(kube_state_metrics_watch_total{job="kube-state-metrics",result="error"}[5m])) /  sum(rate(kube_state_metrics_watch_total{job="kube-state-metrics"}[5m])))  > 0.01
  #     for: 15m
  #     labels:
  #       severity: critical
  - name: node-exporter
    rules:
    - alert: NodeFilesystemSpaceFillingUp
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
          has only {{ printf "%.2f" $value }}% available space left and is filling
          up.
        summary: Filesystem is predicted to run out of space within the next 24 hours.
      expr: |
        ( node_filesystem_avail_bytes{fstype!=""} / node_filesystem_size_bytes{fstype!=""} * 100 < 40 and predict_linear( node_filesystem_avail_bytes{fstype!=""}[6h], 24*60*60) < 0 and  node_filesystem_readonly{fstype!=""} == 0  )
      for: 1h
      labels:
        severity: warning
    - alert: NodeFilesystemSpaceFillingUp
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
          has only {{ printf "%.2f" $value }}% available space left and is filling
          up fast.
        summary: Filesystem is predicted to run out of space within the next 4 hours.
      expr: |
        ( node_filesystem_avail_bytes{fstype!=""} / node_filesystem_size_bytes{fstype!=""} * 100 < 20  and  predict_linear(node_filesystem_avail_bytes{fstype!=""}[6h], 4*60*60) < 0 and  node_filesystem_readonly{fstype!=""} == 0  )
      for: 1h
      labels:
        severity: critical
    - alert: NodeFilesystemAlmostOutOfSpace
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
          has only {{ printf "%.2f" $value }}% available space left.
        summary: Filesystem has less than 5% space left.
      expr: |
        (node_filesystem_avail_bytes{fstype!=""} / node_filesystem_size_bytes{fstype!=""} * 100 < 5 and node_filesystem_readonly{fstype!=""} == 0 )
      for: 1h
      labels:
        severity: warning
    - alert: NodeFilesystemAlmostOutOfSpace
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
          has only {{ printf "%.2f" $value }}% available space left.
        summary: Filesystem has less than 3% space left.
      expr: |
        (node_filesystem_avail_bytes{fstype!=""} / node_filesystem_size_bytes{fstype!=""} * 100 < 3 and  node_filesystem_readonly{fstype!=""} == 0)
      for: 1h
      labels:
        severity: critical
    - alert: NodeFilesystemFilesFillingUp
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
          has only {{ printf "%.2f" $value }}% available inodes left and is filling
          up.
        summary: Filesystem is predicted to run out of inodes within the next 24 hours.
      expr: |
        (node_filesystem_files_free{fstype!=""} / node_filesystem_files{fstype!=""} * 100 < 40 and  predict_linear( node_filesystem_files_free{fstype!=""}[6h], 24*60*60) < 0  and  node_filesystem_readonly{fstype!=""} == 0  )
      for: 1h
      labels:
        severity: warning
    - alert: NodeFilesystemFilesFillingUp
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
          has only {{ printf "%.2f" $value }}% available inodes left and is filling
          up fast.
        summary: Filesystem is predicted to run out of inodes within the next 4 hours.
      expr: |
        (node_filesystem_files_free{fstype!=""} / node_filesystem_files{fstype!=""} * 100 < 20 and  predict_linear( node_filesystem_files_free{fstype!=""}[6h], 4*60*60) < 0  and  node_filesystem_readonly{fstype!=""} == 0  )
      for: 1h
      labels:
        severity: critical
    - alert: NodeFilesystemAlmostOutOfFiles
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
          has only {{ printf "%.2f" $value }}% available inodes left.
        summary: Filesystem has less than 5% inodes left.
      expr: |
        (node_filesystem_files_free{fstype!=""} / node_filesystem_files{fstype!=""} * 100 < 5  and node_filesystem_readonly{fstype!=""} == 0  )
      for: 1h
      labels:
        severity: warning
    - alert: NodeFilesystemAlmostOutOfFiles
      annotations:
        description: Filesystem on {{ $labels.device }} at {{ $labels.instance }}
          has only {{ printf "%.2f" $value }}% available inodes left.
        summary: Filesystem has less than 3% inodes left.
      expr: |
        ( node_filesystem_files_free{fstype!=""} / node_filesystem_files{fstype!=""} * 100 < 3  and  node_filesystem_readonly{fstype!=""} == 0 )
      for: 1h
      labels:
        severity: critical
    - alert: NodeNetworkReceiveErrs
      annotations:
        description: '{{ $labels.instance }} interface {{ $labels.device }} has encountered
          {{ printf "%.0f" $value }} receive errors in the last two minutes.'
        summary: Network interface is reporting many receive errors.
      expr: |
        increase(node_network_receive_errs_total[2m]) > 10
      for: 1h
      labels:
        severity: warning
    - alert: NodeNetworkTransmitErrs
      annotations:
        description: '{{ $labels.instance }} interface {{ $labels.device }} has encountered
          {{ printf "%.0f" $value }} transmit errors in the last two minutes.'
        summary: Network interface is reporting many transmit errors.
      expr: |
        increase(node_network_transmit_errs_total[2m]) > 10
      for: 1h
      labels:
        severity: warning
  - name: kubernetes-apps
    rules:
    - alert: KubePodCrashLooping
      annotations:
        message: Pod {{ $labels.namespace }}/{{ $labels.pod }} ({{ $labels.container
          }}) is restarting {{ printf "%.2f" $value }} times / 5 minutes.
      expr: |
        rate(kube_pod_container_status_restarts_total{}[5m]) * 60 * 5 > 0
      for: 2m
      labels:
        severity: critical
    - alert: KubePodNotReady
      annotations:
        message: Pod {{ $labels.namespace }}/{{ $labels.pod }} has been in a non-ready
          state for longer than 15 minutes.
      expr: |
        sum by (namespace, pod) (max by(namespace, pod) (kube_pod_status_phase{phase=~"Pending|Unknown"}) * on(namespace, pod) group_left(owner_kind) max by(namespace, pod, owner_kind) (kube_pod_owner{owner_kind!="Job"})) > 0
      for: 15m
      labels:
        severity: critical
    - alert: KubeDeploymentGenerationMismatch
      annotations:
        message: Deployment generation for {{ $labels.namespace }}/{{ $labels.deployment
          }} does not match, this indicates that the Deployment has failed but has
          not been rolled back.
      expr: |
        kube_deployment_status_observed_generation{} !=  kube_deployment_metadata_generation{}
      for: 15m
      labels:
        severity: critical
    - alert: KubeDeploymentReplicasMismatch
      annotations:
        message: Deployment {{ $labels.namespace }}/{{ $labels.deployment }} has not
          matched the expected number of replicas for longer than 15 minutes.
      expr: |
        kube_deployment_spec_replicas{} != kube_deployment_status_replicas_available{}
      for: 15m
      labels:
        severity: critical
    - alert: KubeStatefulSetReplicasMismatch
      annotations:
        message: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} has
          not matched the expected number of replicas for longer than 15 minutes.
      expr: |
        kube_statefulset_status_replicas_ready{}
          !=
        kube_statefulset_status_replicas{}
      for: 15m
      labels:
        severity: critical
    - alert: KubeStatefulSetGenerationMismatch
      annotations:
        message: StatefulSet generation for {{ $labels.namespace }}/{{ $labels.statefulset
          }} does not match, this indicates that the StatefulSet has failed but has
          not been rolled back.
      expr: |
        kube_statefulset_status_observed_generation{}
          !=
        kube_statefulset_metadata_generation{}
      for: 15m
      labels:
        severity: critical
    - alert: KubeStatefulSetUpdateNotRolledOut
      annotations:
        message: StatefulSet {{ $labels.namespace }}/{{ $labels.statefulset }} update
          has not been rolled out.
      expr: |
        max without (revision) (  kube_statefulset_status_current_revision{}  unless  kube_statefulset_status_update_revision{} ) * ( kube_statefulset_replicas{}  !=   kube_statefulset_status_replicas_updated{}  )
      for: 15m
      labels:
        severity: critical
    - alert: KubeDaemonSetRolloutStuck
      annotations:
        message: Only {{ $value | humanizePercentage }} of the desired Pods of DaemonSet
          {{ $labels.namespace }}/{{ $labels.daemonset }} are scheduled and ready.
      expr: |
        kube_daemonset_status_number_ready{}  /  kube_daemonset_status_desired_number_scheduled{} < 1.00
      for: 15m
      labels:
        severity: critical
    - alert: KubeContainerWaiting
      annotations:
        message: Pod {{ $labels.namespace }}/{{ $labels.pod }} container {{ $labels.container}}
          has been in waiting state for longer than 1 hour.
      expr: |
        sum by (namespace, pod, container) (kube_pod_container_status_waiting_reason{}) > 0
      for: 1h
      labels:
        severity: warning
    - alert: KubeDaemonSetNotScheduled
      annotations:
        message: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset
          }} are not scheduled.'
      expr: |
        kube_daemonset_status_desired_number_scheduled{}  -  kube_daemonset_status_current_number_scheduled{} > 0
      for: 10m
      labels:
        severity: warning
    - alert: KubeDaemonSetMisScheduled
      annotations:
        message: '{{ $value }} Pods of DaemonSet {{ $labels.namespace }}/{{ $labels.daemonset
          }} are running where they are not supposed to run.'
      expr: |
        kube_daemonset_status_number_misscheduled{} > 0
      for: 10m
      labels:
        severity: warning
    - alert: KubeCronJobRunning
      annotations:
        message: CronJob {{ $labels.namespace }}/{{ $labels.cronjob }} is taking more
          than 1h to complete.
      expr: |
        time() - kube_cronjob_next_schedule_time{} > 3600
      for: 1h
      labels:
        severity: warning
    - alert: KubeJobCompletion
      annotations:
        message: Job {{ $labels.namespace }}/{{ $labels.job_name }} is taking more
          than one hour to complete.
      expr: |
        kube_job_spec_completions{} - kube_job_status_succeeded{}  > 0
      for: 1h
      labels:
        severity: warning
    - alert: KubeJobFailed
      annotations:
        message: Job {{ $labels.namespace }}/{{ $labels.job_name }} failed to complete.
      expr: |
        kube_job_status_failed{}  > 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeHpaReplicasMismatch
      annotations:
        message: HPA {{ $labels.namespace }}/{{ $labels.hpa }} has not matched the
          desired number of replicas for longer than 15 minutes.
      expr: |
        (kube_hpa_status_desired_replicas{}  !=  kube_hpa_status_current_replicas{})  and changes(kube_hpa_status_current_replicas[15m]) == 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeHpaMaxedOut
      annotations:
        message: HPA {{ $labels.namespace }}/{{ $labels.hpa }} has been running at
          max replicas for longer than 15 minutes.
      expr: |
        kube_hpa_status_current_replicas{job="kube-state-metrics"}  ==  kube_hpa_spec_max_replicas{job="kube-state-metrics"}
      for: 15m
      labels:
        severity: warning
  - name: kubernetes-resources
    rules:
    - alert: KubeCPUOvercommit
      annotations:
        message: Cluster has overcommitted CPU resource requests for Pods and cannot
          tolerate node failure.
      expr: |
        sum(namespace:kube_pod_container_resource_requests_cpu_cores:sum)  /  sum(kube_node_status_allocatable_cpu_cores) > (count(kube_node_status_allocatable_cpu_cores)-1) / count(kube_node_status_allocatable_cpu_cores)
      for: 5m
      labels:
        severity: warning
    - alert: KubeMemOvercommit
      annotations:
        message: Cluster has overcommitted memory resource requests for Pods and cannot
          tolerate node failure.
      expr: |
        sum(namespace:kube_pod_container_resource_requests_memory_bytes:sum) / sum(kube_node_status_allocatable_memory_bytes)  > (count(kube_node_status_allocatable_memory_bytes)-1) /  count(kube_node_status_allocatable_memory_bytes)
      for: 5m
      labels:
        severity: warning
    - alert: KubeCPUOvercommit
      annotations:
        message: Cluster has overcommitted CPU resource requests for Namespaces.
      expr: |
        sum(kube_resourcequota{type="hard", resource="cpu"})  /  sum(kube_node_status_allocatable_cpu_cores)  > 1.5
      for: 5m
      labels:
        severity: warning
    - alert: KubeMemOvercommit
      annotations:
        message: Cluster has overcommitted memory resource requests for Namespaces.
      expr: |
        sum(kube_resourcequota{job="kube-state-metrics", type="hard", resource="memory"})  /  sum(kube_node_status_allocatable_memory_bytes{job="node-exporter"})  > 1.5
      for: 5m
      labels:
        severity: warning
    - alert: KubeQuotaExceeded
      annotations:
        message: Namespace {{ $labels.namespace }} is using {{ $value | humanizePercentage
          }} of its {{ $labels.resource }} quota.
      expr: |
        kube_resourcequota{job="kube-state-metrics", type="used"}  / ignoring(instance, job, type)  (kube_resourcequota{job="kube-state-metrics", type="hard"} > 0)  > 0.90
      for: 15m
      labels:
        severity: warning
        ##- alert: CPUThrottlingHigh
        ##annotations:
        ##message: '{{ $value | humanizePercentage }} throttling of CPU in namespace
        ##{{ $labels.namespace }} for container {{ $labels.container }} in pod {{
        ##$labels.pod }}.'
        ##expr: |
        ##sum(increase(container_cpu_cfs_throttled_periods_total{container!="", }[5m])) by (container, pod, namespace)  /  sum(increase(container_cpu_cfs_periods_total{}[5m])) by (container, pod, namespace) > ( 25 / 100 )
        ##for: 15m
        ##labels:
        ##severity: warning
  - name: kubernetes-storage
    rules:
    - alert: KubePersistentVolumeUsageCritical
      annotations:
        message: The PersistentVolume claimed by {{ $labels.persistentvolumeclaim
          }} in Namespace {{ $labels.namespace }} is only {{ $value | humanizePercentage
          }} free.
      expr: |
        kubelet_volume_stats_available_bytes{}  /  kubelet_volume_stats_capacity_bytes{}  < 0.03
      for: 1m
      labels:
        severity: critical
    - alert: KubePersistentVolumeFullInFourDays
      annotations:
        message: Based on recent sampling, the PersistentVolume claimed by {{ $labels.persistentvolumeclaim
          }} in Namespace {{ $labels.namespace }} is expected to fill up within four
          days. Currently {{ $value | humanizePercentage }} is available.
      expr: |
        ( kubelet_volume_stats_available_bytes{} / kubelet_volume_stats_capacity_bytes{} ) < 0.15 and  predict_linear(kubelet_volume_stats_available_bytes{}[6h], 4 * 24 * 3600) < 0
      for: 1h
      labels:
        severity: critical
    - alert: KubePersistentVolumeErrors
      annotations:
        message: The persistent volume {{ $labels.persistentvolume }} has status {{
          $labels.phase }}.
      expr: |
        kube_persistentvolume_status_phase{phase=~"Failed|Pending"} > 0
      for: 5m
      labels:
        severity: critical
  - name: kubernetes-system
    rules:
            ##    - alert: KubeVersionMismatch
            ##annotations:
            #message: There are {{ $value }} different semantic versions of Kubernetes
            #components running.
            #expr: |
            #count(count by (gitVersion) (label_replace(kubernetes_build_info{job!~"kube-dns|coredns"},"gitVersion","$1","gitVersion","(v[0-9]*.[0-9]*.[0-9]*).*"))) > 1
            #for: 15m
            #labels:
            #severity: warning
    - alert: KubeClientErrors
      annotations:
        message: Kubernetes API server client '{{ $labels.job }}/{{ $labels.instance
          }}' is experiencing {{ $value | humanizePercentage }} errors.'
      expr: |
        (sum(rate(rest_client_requests_total{code=~"5.."}[5m])) by (instance, job)  / sum(rate(rest_client_requests_total[5m])) by (instance, job))  > 0.01
      for: 15m
      labels:
        severity: warning
  - name: kube-apiserver-error
    rules:
    - alert: ErrorBudgetBurn
      annotations:
      expr: |
        (status_class_5xx:apiserver_request_total:ratio_rate1h{job="kubernetes-apiservers"} > (14.4*0.010000)  and  status_class_5xx:apiserver_request_total:ratio_rate5m{job="kubernetes-apiservers"} > (14.4*0.010000) ) or ( status_class_5xx:apiserver_request_total:ratio_rate6h{job="kubernetes-apiservers"} > (6*0.010000)  and status_class_5xx:apiserver_request_total:ratio_rate30m{job="kubernetes-apiservers"} > (6*0.010000) )
      labels:
        job: kubernetes-apiservers
        severity: critical
    - alert: ErrorBudgetBurn
      annotations:
      expr: |
        (status_class_5xx:apiserver_request_total:ratio_rate1d{job="kubernetes-apiservers"} > (3*0.010000)  and  status_class_5xx:apiserver_request_total:ratio_rate2h{job="kubernetes-apiservers"} > (3*0.010000) ) or ( status_class_5xx:apiserver_request_total:ratio_rate3d{job="kubernetes-apiservers"} > (0.010000)  and  status_class_5xx:apiserver_request_total:ratio_rate6h{job="kubernetes-apiservers"} > (0.010000)  )
      labels:
        job: kubernetes-apiservers
        severity: warning
    - expr: |
        sum by (status_class) ( label_replace( rate(apiserver_request_total{job="kubernetes-apiservers"}[5m] ), "status_class", "${1}xx", "code", "([0-9])..") )
      labels:
        job: kubernetes-apiservers
      record: status_class:apiserver_request_total:rate5m
    - expr: |
        sum by (status_class) (label_replace( rate(apiserver_request_total{job="kubernetes-apiservers"}[30m]), "status_class", "${1}xx", "code", "([0-9])..") )
      labels:
        job: kubernetes-apiservers
      record: status_class:apiserver_request_total:rate30m
    - expr: |
        sum by (status_class) ( label_replace( rate(apiserver_request_total{job="kubernetes-apiservers"}[1h]  ), "status_class", "${1}xx", "code", "([0-9])..")  )
      labels:
        job: kubernetes-apiservers
      record: status_class:apiserver_request_total:rate1h
    - expr: |
        sum by (status_class) ( label_replace(  rate(apiserver_request_total{job="kubernetes-apiservers"}[2h] ), "status_class", "${1}xx", "code", "([0-9])..")  )
      labels:
        job: kubernetes-apiservers
      record: status_class:apiserver_request_total:rate2h
    - expr: |
        sum by (status_class) ( label_replace( rate(apiserver_request_total{job="kubernetes-apiservers"}[6h] ), "status_class", "${1}xx", "code", "([0-9])..") )
      labels:
        job: kubernetes-apiservers
      record: status_class:apiserver_request_total:rate6h
    - expr: |
        sum by (status_class) (label_replace( rate(apiserver_request_total{job="kubernetes-apiservers"}[1d] ), "status_class", "${1}xx", "code", "([0-9])..") )
      labels:
        job: kubernetes-apiservers
      record: status_class:apiserver_request_total:rate1d
    - expr: |
        sum by (status_class) (label_replace( rate(apiserver_request_total{job="kubernetes-apiservers"}[3d] ), "status_class", "${1}xx", "code", "([0-9]).."))
      labels:
        job: kubernetes-apiservers
      record: status_class:apiserver_request_total:rate3d
    - expr: |
        sum(status_class:apiserver_request_total:rate5m{job="kubernetes-apiservers",status_class="5xx"}) / sum(status_class:apiserver_request_total:rate5m{job="kubernetes-apiservers"})
      labels:
        job: kubernetes-apiservers
      record: status_class_5xx:apiserver_request_total:ratio_rate5m
    - expr: |
        sum(status_class:apiserver_request_total:rate30m{job="kubernetes-apiservers",status_class="5xx"})  / sum(status_class:apiserver_request_total:rate30m{job="kubernetes-apiservers"})
      labels:
        job: kubernetes-apiservers
      record: status_class_5xx:apiserver_request_total:ratio_rate30m
    - expr: |
        sum(status_class:apiserver_request_total:rate1h{job="kubernetes-apiservers",status_class="5xx"})  /  sum(status_class:apiserver_request_total:rate1h{job="kubernetes-apiservers"})
      labels:
        job: kubernetes-apiservers
      record: status_class_5xx:apiserver_request_total:ratio_rate1h
    - expr: |
        sum(status_class:apiserver_request_total:rate2h{job="kubernetes-apiservers",status_class="5xx"}) /  sum(status_class:apiserver_request_total:rate2h{job="kubernetes-apiservers"})
      labels:
        job: kubernetes-apiservers
      record: status_class_5xx:apiserver_request_total:ratio_rate2h
    - expr: |
        sum(status_class:apiserver_request_total:rate6h{job="kubernetes-apiservers",status_class="5xx"}) /  sum(status_class:apiserver_request_total:rate6h{job="kubernetes-apiservers"})
      labels:
        job: kubernetes-apiservers
      record: status_class_5xx:apiserver_request_total:ratio_rate6h
    - expr: |
        sum(status_class:apiserver_request_total:rate1d{job="kubernetes-apiservers",status_class="5xx"}) /  sum(status_class:apiserver_request_total:rate1d{job="kubernetes-apiservers"})
      labels:
        job: kubernetes-apiservers
      record: status_class_5xx:apiserver_request_total:ratio_rate1d
    - expr: |
        sum(status_class:apiserver_request_total:rate3d{job="kubernetes-apiservers",status_class="5xx"}) / sum(status_class:apiserver_request_total:rate3d{job="kubernetes-apiservers"})
      labels:
        job: kubernetes-apiservers
      record: status_class_5xx:apiserver_request_total:ratio_rate3d
  - name: kubernetes-system-apiserver
    rules:
    - alert: KubeAPILatencyHigh
      annotations:
        message: The API server has an abnormal latency of {{ $value }} seconds for
          {{ $labels.verb }} {{ $labels.resource }}.
      expr: |
        ( cluster:apiserver_request_duration_seconds:mean5m{job="kubernetes-apiservers"}  >  on (verb) group_left() ( avg by (verb) ( cluster:apiserver_request_duration_seconds:mean5m{job="kubernetes-apiservers"} >= 0) +  2*stddev by (verb) (cluster:apiserver_request_duration_seconds:mean5m{job="kubernetes-apiservers"} >= 0) )) > on (verb) group_left() 1.2 * avg by (verb) (cluster:apiserver_request_duration_seconds:mean5m{job="kubernetes-apiservers"} >= 0) and on (verb,resource) cluster_quantile:apiserver_request_duration_seconds:histogram_quantile{job="kubernetes-apiservers",quantile="0.99"} >  1
      for: 5m
      labels:
        severity: warning
    - alert: KubeAPILatencyHigh
      annotations:
        message: The API server has a 99th percentile latency of {{ $value }} seconds
          for {{ $labels.verb }} {{ $labels.resource }}.
      expr: |
        cluster_quantile:apiserver_request_duration_seconds:histogram_quantile{job="kubernetes-apiservers",quantile="0.99"} > 4
      for: 10m
      labels:
        severity: critical
    - alert: KubeAPIErrorsHigh
      annotations:
        message: API server is returning errors for {{ $value | humanizePercentage
          }} of requests.
      expr: |
        sum(rate(apiserver_request_total{job="kubernetes-apiservers",code=~"5.."}[5m])) / sum(rate(apiserver_request_total{job="kubernetes-apiservers"}[5m])) > 0.03
      for: 10m
      labels:
        severity: critical
    - alert: KubeAPIErrorsHigh
      annotations:
        message: API server is returning errors for {{ $value | humanizePercentage
          }} of requests.
      expr: |
        sum(rate(apiserver_request_total{job="kubernetes-apiservers",code=~"5.."}[5m]))  /  sum(rate(apiserver_request_total{job="kubernetes-apiservers"}[5m])) > 0.01
      for: 10m
      labels:
        severity: warning
    - alert: KubeAPIErrorsHigh
      annotations:
        message: API server is returning errors for {{ $value | humanizePercentage
          }} of requests for {{ $labels.verb }} {{ $labels.resource }} {{ $labels.subresource
          }}.
      expr: |
        sum(rate(apiserver_request_total{job="kubernetes-apiservers",code=~"5.."}[5m])) by (resource,subresource,verb) / sum(rate(apiserver_request_total{job="kubernetes-apiservers"}[5m])) by (resource,subresource,verb) > 0.10
      for: 10m
      labels:
        severity: critical
    - alert: KubeAPIErrorsHigh
      annotations:
        message: API server is returning errors for {{ $value | humanizePercentage
          }} of requests for {{ $labels.verb }} {{ $labels.resource }} {{ $labels.subresource
          }}.
      expr: |
        sum(rate(apiserver_request_total{job="kubernetes-apiservers",code=~"5.."}[5m])) by (resource,subresource,verb) / sum(rate(apiserver_request_total{job="kubernetes-apiservers"}[5m])) by (resource,subresource,verb) > 0.05
      for: 10m
      labels:
        severity: warning
    - alert: KubeClientCertificateExpiration
      annotations:
        message: A client certificate used to authenticate to the apiserver is expiring
          in less than 7.0 days.
      expr: |
        apiserver_client_certificate_expiration_seconds_count{job="kubernetes-apiservers"} > 0 and on(job) histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="kubernetes-apiservers"}[5m]))) < 604800
      labels:
        severity: warning
    - alert: KubeClientCertificateExpiration
      annotations:
        message: A client certificate used to authenticate to the apiserver is expiring
          in less than 24.0 hours.
      expr: |
        apiserver_client_certificate_expiration_seconds_count{job="kubernetes-apiservers"} > 0 and on(job) histogram_quantile(0.01, sum by (job, le) (rate(apiserver_client_certificate_expiration_seconds_bucket{job="kubernetes-apiservers"}[5m]))) < 86400
      labels:
        severity: critical
    - alert: KubeAPIDown
      annotations:
        message: KubeAPI has disappeared from Prometheus target discovery.
      expr: |
        absent(up{job="kubernetes-apiservers"} == 1)
      for: 15m
      labels:
        severity: critical
  - name: kubernetes-system-kubelet
    rules:
    - alert: KubeNodeNotReady
      annotations:
        message: '{{ $labels.node }} has been unready for more than 15 minutes.'
      expr: |
        kube_node_status_condition{condition="Ready",status="true"} == 0
      for: 15m
      labels:
        severity: warning
    - alert: KubeNodeUnreachable
      annotations:
        message: '{{ $labels.node }} is unreachable and some workloads may be rescheduled.'
      expr: |
        (kube_node_spec_taint{key="node.kubernetes.io/unreachable",effect="NoSchedule"} unless ignoring(key,value) kube_node_spec_taint{key="ToBeDeletedByClusterAutoscaler"}) == 1
      labels:
        severity: warning
    - alert: KubeletTooManyPods
      annotations:
        message: Kubelet '{{ $labels.node }}' is running at {{ $value | humanizePercentage
          }} of its Pod capacity.
      expr: |
        max(max(kubelet_running_pod_count{metrics_path="/metrics"}) by(instance) * on(instance) group_left(node) kubelet_node_name{metrics_path="/metrics"}) by(node) / max(kube_node_status_capacity_pods{}) by(node) > 0.95
      for: 15m
      labels:
        severity: warning

  - name: general.rules
    rules:
    - alert: TargetDown
      annotations:
        message: '{{ printf "%.4g" $value }}% of the {{ $labels.job }}/{{ $labels.service
          }} targets in {{ $labels.namespace }} namespace are down.'
      expr: 100 * (count(up == 0) BY (job, namespace, service) / count(up) BY (job, namespace, service)) > 10
      for: 10m
      labels:
        severity: warning
        #- alert: Watchdog
        #annotations:
        #message: |
        #  This is an alert meant to ensure that the entire alerting pipeline is functional.
        #  This alert is always firing, therefore it should always be firing in Alertmanager
        #  and always fire against a receiver. There are integrations with various notification
        #  mechanisms that send a notification when this alert is not firing. For example the
        #  "DeadMansSnitch" integration in PagerDuty.
        #expr: vector(1)
        #labels:
        # severity: none
  - name: node-time
    rules:
    - alert: ClockSkewDetected
      annotations:
        message: Clock skew detected on node-exporter {{ $labels.namespace }}/{{ $labels.pod
          }}. Ensure NTP is configured correctly on this host.
      expr: |
        abs(node_timex_offset_seconds{}) > 0.05
      for: 2m
      labels:
        severity: warning
  - name: node-network
    rules:
    - alert: NodeNetworkInterfaceFlapping
      annotations:
        message: Network interface "{{ $labels.device }}" changing it's up status
          often on node-exporter {{ $labels.namespace }}/{{ $labels.pod }}"
      expr: |
        changes(node_network_up{device!~"veth.+"}[2m]) > 2
      for: 2m
      labels:
        severity: warning
